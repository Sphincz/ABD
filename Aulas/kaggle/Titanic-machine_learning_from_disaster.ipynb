{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine learning from disaster\n",
    "\n",
    "## Kaggle getting start prediction competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descrição&nbsp;do&nbsp;trabalho\n",
    "\n",
    "Neste _notebook_ vamos fazer resolver o _challenge_ \"_Titanic: Machine learning from disaster_\" do [kaggle](https://www.kaggle.com/c/titanic), para exemplificar o uso do python pandas aplicado a um problema de _machine learning_.\n",
    "\n",
    "Resumo do notebook:\n",
    "\n",
    "1. [Descrição do dataset](#Descrição&nbsp;do&nbsp;dataset)\n",
    "<br>Informação detalhada sobre o _dataset_.<br><br>\n",
    "2. [Importar bibliotecas e dataset](#Importar&nbsp;bibliotecas&nbsp;e&nbsp;dataset)\n",
    "<br> Importar as bibliotecas necessárias e importar o _dataset_ do kaggle.<br><br>\n",
    "3. [Análise exploratória do dataset](# Análise&nbsp;exploratória&nbsp;do&nbsp;dataset) \n",
    "<br> Pequeno conjunto de operações para ter uma ideia das características do _dataset_. <br><br>\n",
    "4. [Modelo e aprendizagem supervisionada](#Modelo&nbsp;e&nbsp;aprendizagem&nbsp;supervisionada) \n",
    "<br>Aplicação de um conjunto de modelos da aprendizagem supervisionada no _dataset_ e respectiva avaliação.<br><br>\n",
    "5. [Output para submissão](#Output&nbsp;para&nbsp;submissão) \n",
    "<br>Preparação do ficheiro para submissão na competição do [kaggle](https://www.kaggle.com/c/titanic). Serão feitas duas submissões:<br>\n",
    " - totalmente aleatória <br>\n",
    " - usando o melhor modelo treinado no ponto anterior.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Descrição&nbsp;do&nbsp;dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The data has been split into two groups:\n",
    "\n",
    "- training set (train.csv)\n",
    "- test set (test.csv)\n",
    "\n",
    "\n",
    "\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "|:-|:-|:-|\n",
    "|survival |\tSurvival |\t0 = No, 1 = Yes |\n",
    "|pclass |\tTicket class | \t1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "|sex |\tSex | | \n",
    "|Age |\tAge in years \t| | \n",
    "|sibsp |\t# of siblings / spouses aboard the Titanic \t | |\n",
    "|parch |\t# of parents / children aboard the Titanic \t | |\n",
    "|ticket |\tTicket number \t | |\n",
    "|fare |\tPassenger fare \t | |\n",
    "|cabin |\tCabin number \t | |\n",
    "|embarked |\tPort of Embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
    "\n",
    "## Variable Notes\n",
    "\n",
    "**pclass**: A proxy for socio-economic status (SES)<br>\n",
    "1st = Upper <br>\n",
    "2nd = Middle <br>\n",
    "3rd = Lower <br>\n",
    "\n",
    "**age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
    "\n",
    "**sibsp**: The dataset defines family relations in this way...<br>\n",
    "Sibling = brother, sister, stepbrother, stepsister<br>\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "**parch**: The dataset defines family relations in this way...<br>\n",
    "Parent = mother, father<br>\n",
    "Child = daughter, son, stepdaughter, stepson<br>\n",
    "Some children travelled only with a nanny, therefore parch=0 for them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topo](#Descrição&nbsp;do&nbsp;trabalho)\n",
    "\n",
    "---\n",
    "\n",
    "# Importar&nbsp;bibliotecas&nbsp;e&nbsp;dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir dois datasets:\n",
    "\n",
    "- `full`: constituído pelo conjunto _training set_ e _test set_\n",
    "- `titanic`: constituído pelo _training set_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = train.append(test, ignore_index=True)\n",
    "titanic = full[:891]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topo](#Descrição&nbsp;do&nbsp;trabalho)\n",
    "\n",
    "---\n",
    "\n",
    "# Análise&nbsp;exploratória&nbsp;do&nbsp;dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlação entre as variáveis\n",
    "\n",
    "O gráfico seguinte mostra a matriz de correlação como um _heatmap_ para ilustrar a dependência das diferentes variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize =( 8 , 7 ))\n",
    "sns.heatmap(titanic.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuição das variáveis\n",
    "\n",
    "A função seguinte permite ilustrar a distribuição de uma variável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função da idade e sexo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Age'\n",
    "target = 'Survived'\n",
    "row = 'Sex'\n",
    "facet = sns.FacetGrid(titanic, hue=target, aspect=3, row=row)\n",
    "facet.map(sns.kdeplot, var, shade=True)\n",
    "facet.set(xlim=( 0 , titanic[var].max()))\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função do preço do bilhete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'Fare'\n",
    "target = 'Survived'\n",
    "row = 'Sex'\n",
    "facet = sns.FacetGrid(titanic, hue=target, aspect=3, row=row)\n",
    "facet.map(sns.kdeplot, var, shade=True)\n",
    "facet.set(xlim=( 0 , titanic[var].max()))\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função da porta de embarque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'Embarked'\n",
    "target = 'Survived'\n",
    "facet = sns.FacetGrid( titanic )\n",
    "facet.map( sns.barplot , cat , target )\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função da classe do bilhete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'Pclass'\n",
    "target = 'Survived'\n",
    "facet = sns.FacetGrid( titanic )\n",
    "facet.map( sns.barplot , cat , target )\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função do número de familiares directos (siblings/spouses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'SibSp'\n",
    "target = 'Survived'\n",
    "facet = sns.FacetGrid( titanic )\n",
    "facet.map( sns.barplot , cat , target )\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de sobrevivência em função do número de famíliares de geração anterior e seguinte (parents/children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'Parch'\n",
    "target = 'Survived'\n",
    "facet = sns.FacetGrid( titanic )\n",
    "facet.map( sns.barplot , cat , target )\n",
    "facet.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topo](#Descrição&nbsp;do&nbsp;trabalho)\n",
    "\n",
    "---\n",
    "\n",
    "# Transformar&nbsp;o&nbsp;dataset\n",
    "\n",
    "Antes de aplicar algoritmos de _machine learning_, serão realizadas as seguintes transformações do dataset:\n",
    "\n",
    "- [Transformar categorias em números](#Transformar&nbsp;categorias&nbsp;em&nbsp;números)\n",
    "- [Preencher os missing values](#Preencher&nbsp;os&nbsp;missing&nbsp;values)\n",
    "- [Criar o dataset final para o modelo](#Criar&nbsp;o&nbsp;dataset&nbsp;final&nbsp;para&nbsp;o&nbsp;modelo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar&nbsp;categorias&nbsp;em&nbsp;números"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar Sex em valores binários: 0 ou 1\n",
    "sex = pd.Series( np.where( full.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\n",
    "sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma nova variável numérica única para cada sítio de embarque\n",
    "embarked = pd.get_dummies( full.Embarked , prefix='Embarked' )\n",
    "embarked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma nova variável numérica única para cada classe do bilhete\n",
    "pclass = pd.get_dummies( full.Pclass , prefix='Pclass' )\n",
    "pclass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preencher&nbsp;os&nbsp;missing&nbsp;values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Novo dataset\n",
    "filledin = pd.DataFrame()\n",
    "\n",
    "# Preencher os missing values da idade com a idade média dos passageiros\n",
    "filledin[ 'Age' ] = full.Age.fillna( full.Age.mean() )\n",
    "\n",
    "# Preencher o valor da tarifa do bilhete com o preço médio dos bilhetes\n",
    "filledin[ 'Fare' ] = full.Fare.fillna( full.Fare.mean() )\n",
    "\n",
    "filledin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar&nbsp;o&nbsp;dataset&nbsp;final&nbsp;para&nbsp;o&nbsp;modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = pd.concat( [ filledin , embarked , pclass, sex ] , axis=1 )\n",
    "full_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topo](#Descrição&nbsp;do&nbsp;trabalho)\n",
    "\n",
    "---\n",
    "\n",
    "# Modelo&nbsp;e&nbsp;aprendizagem&nbsp;supervisionada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar os modelos e definição dos datasets para os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Funções do módulo sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de treino e teste obtido a partir do dataset final:  `full_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criar os datasets para treinar, validar e testar os modelos\n",
    "train_valid_X = full_model[ 0:891 ]\n",
    "train_valid_y = titanic.Survived\n",
    "test_X = full_model[ 891: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação em conjunto de teste e treino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X , valid_X , train_y , valid_y = train_test_split( train_valid_X , train_valid_y,  train_size = .7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dimensões dos datasets:')\n",
    "print ('full_model:', full_model.shape)\n",
    "print('train_X:', train_X.shape)\n",
    "print('valid_X:', valid_X.shape)\n",
    "print('train_y:', train_y.shape)\n",
    "print('valid_y:', valid_y.shape)\n",
    "print('test_X:', test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nears neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 2)\n",
    "model.fit( train_X , train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.1)\n",
    "model.fit( train_X , train_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(C=0.1)\n",
    "model.fit( train_X , train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=10)\n",
    "model.fit( train_X , train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier( random_state = 99 )\n",
    "model.fit( train_X , train_y )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit( train_X , train_y )\n",
    "print(\"Score do conjunto de treino:\", model.score( train_X , train_y ))\n",
    "print(\"Score do conjunto de teste:\", model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importância das features no random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.DataFrame( \n",
    "        model.feature_importances_  , \n",
    "        columns = [ 'Importance' ] , \n",
    "        index = train_X.columns \n",
    "    )\n",
    "imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
    "imp.plot( kind = 'barh' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Topo](#Descrição&nbsp;do&nbsp;trabalho)\n",
    "\n",
    "---\n",
    "\n",
    "# Output&nbsp;para&nbsp;submissão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissão aleatória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = np.random.randint(2, size=len(full[891:]))\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y.astype(int) } )\n",
    "test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv( 'titanic_pred_random.csv' , index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissão usando o nosso melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit( train_X , train_y )\n",
    "test_Y = model.predict( test_X )\n",
    "passenger_id = full[891:].PassengerId\n",
    "test = pd.DataFrame( { 'PassengerId': passenger_id , 'Survived': test_Y.astype(int) } )\n",
    "test.shape\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv( 'titanic_pred.csv' , index = False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
